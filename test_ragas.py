import os
import pandas as pd
from dotenv import load_dotenv
load_dotenv()

from graph.graph import app
from ragas import EvaluationDataset, SingleTurnSample, evaluate
from ragas.metrics import Faithfulness, LLMContextRecall, ResponseRelevancy, ContextPrecision
from ragas.llms import LangchainLLMWrapper
from langchain_google_genai import ChatGoogleGenerativeAI

# =========================================================================
# TEST VERÄ° SETÄ° - Lord of the Mysteries SorularÄ±
# =========================================================================

TEST_QUESTIONS = [
    {
        "question": "Fool Pathway'de Sequence 9 Seer'Ä±n yetenekleri nelerdir?",
        "ground_truth": "Seer potionunu iÃ§enler hafÄ±za artÄ±ÅŸÄ±, Spirituality geliÅŸimi, Spirit Vision (ruhani gÃ¶rÃ¼ÅŸ), Divination Arts & Ritualistic Magic yetenekleri ve Danger Intuition (tehlike sezgisi) kazanÄ±r."
    },
    {
        "question": "Sequence 8 Clown hangi fiziksel yeteneklere sahiptir?",
        "ground_truth": "Clown, vÃ¼cutlarÄ± Ã¼zerinde gÃ¼Ã§lÃ¼ kontrol, akrobatik yetenek, mÃ¼kemmel denge, el becerisi ve hÄ±z artÄ±ÅŸÄ± kazanÄ±r. AyrÄ±ca Paper Daggers (kaÄŸÄ±t hanÃ§erler) oluÅŸturabilir."
    },
    {
        "question": "Marionettist'in Spirit Body Threads Manipulation yeteneÄŸi nasÄ±l Ã§alÄ±ÅŸÄ±r?",
        "ground_truth": "Marionettist, 100 metreye kadar Spirit Body Threads'i algÄ±layÄ±p manipÃ¼le edebilir. Hedefin Soul Body, Astral Projection, Body of Heart and Mind ve Ether Body'sini etkileyerek kontrol saÄŸlar."
    },
    {
        "question": "Bizarro Sorcerer'Ä±n Bestowal yeteneÄŸi nedir?",
        "ground_truth": "Bizarro Sorcerer, Worms of Spirit'lerini Marionette'lerine 'hediye' edebilir, bu sayede Marionette'ler Beyonder gÃ¼Ã§lerini kullanabilir. BaÅŸlangÄ±Ã§ta 50 Worms of Spirit ayÄ±rabilirler."
    },
    {
        "question": "Scholar of Yore Historical Void'i nasÄ±l kullanÄ±r?",
        "ground_truth": "Scholar of Yore, Historical Void Borrowing (geÃ§miÅŸ benliÄŸinden gÃ¼Ã§ Ã¶dÃ¼nÃ§ alma), Historical Projection Summoning (geÃ§miÅŸten projeksiyon Ã§aÄŸÄ±rma) ve Historical Void Hiding (Historical Void'de saklanma) yeteneklerine sahiptir."
    },
    {
        "question": "Miracle Invoker nasÄ±l mucize gerÃ§ekleÅŸtirir?",
        "ground_truth": "Miracle Invoker, Ã¶nce baÅŸkalarÄ±nÄ±n dileklerini yerine getirerek gÃ¼Ã§ biriktirir, ardÄ±ndan kendi dilekleri iÃ§in bu birikimi kullanarak mucize yaratÄ±r. Dilekler bozulmaya aÃ§Ä±ktÄ±r ve bÃ¼yÃ¼k dilekler daha fazla bozulur."
    },
]


def run_evaluation():
    """RAG sistemini test et ve RAGAS ile deÄŸerlendir."""
    
    print("="*60)
    print("ğŸ”® LoTM Chatbot - RAGAS DeÄŸerlendirmesi")
    print("="*60)
    
    samples = []
    
    print("\nğŸ“ Test sorularÄ± Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...\n")
    
    for i, test_item in enumerate(TEST_QUESTIONS, 1):
        question = test_item["question"]
        ground_truth = test_item["ground_truth"]
        
        print(f"[{i}/{len(TEST_QUESTIONS)}] Soru: {question[:50]}...")
        
        try:
            # Sisteme soruyu sor
            result = app.invoke({"question": question})
            
            answer = result.get("generation", "")
            docs = result.get("documents", [])
            
            # Context'leri al
            context_list = [doc.page_content for doc in docs]
            
            # RAGAS SingleTurnSample oluÅŸtur
            sample = SingleTurnSample(
                user_input=question,
                response=answer,
                retrieved_contexts=context_list,
                reference=ground_truth
            )
            samples.append(sample)
            
            print(f"   âœ… Cevap alÄ±ndÄ± ({len(docs)} belge bulundu)")
            
        except Exception as e:
            print(f"   âŒ Hata: {e}")
    
    # RAGAS Dataset oluÅŸtur
    print("\n" + "="*60)
    print("ğŸ“Š RAGAS DeÄŸerlendirmesi BaÅŸlÄ±yor...")
    print("="*60)
    
    eval_dataset = EvaluationDataset(samples=samples)
    
    # Gemini LLM wrapper
    gemini_llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)
    evaluator_llm = LangchainLLMWrapper(gemini_llm)
    
    # Metrikleri ayarla
    faithfulness_metric = Faithfulness(llm=evaluator_llm)
    context_recall_metric = LLMContextRecall(llm=evaluator_llm)
    relevancy_metric = ResponseRelevancy(llm=evaluator_llm)
    precision_metric = ContextPrecision(llm=evaluator_llm)
    
    metrics = [
        faithfulness_metric,    # Cevap belgelerden mi geldi?
        context_recall_metric,  # Bilgiyi bulma baÅŸarÄ±sÄ± (Retrieval Recall)
        relevancy_metric,       # Cevap soruyla ne kadar alakalÄ±?
        precision_metric,       # Context'in doÄŸruluÄŸu
    ]
    
    print("\nâ³ DeÄŸerlendirme yapÄ±lÄ±yor (bu birkaÃ§ dakika sÃ¼rebilir)...\n")
    
    try:
        results = evaluate(
            dataset=eval_dataset,
            metrics=metrics,
        )
        
        # Rapor
        print("\n" + "="*60)
        print("ğŸ“ˆ DOÄRULUK RAPORU")
        print("="*60)
        
        print("\nğŸ¯ GENEL SKORLAR:")
        print("-"*40)
        
        # DataFrame'den sonuÃ§larÄ± al
        df = results.to_pandas()
        
        # Her metrik iÃ§in ortalama hesapla
        metric_columns = ['faithfulness', 'llm_context_recall', 'response_relevancy', 'context_precision']
        
        for col in metric_columns:
            if col in df.columns:
                score = df[col].mean()
                emoji = "ğŸŸ¢" if score >= 0.7 else "ğŸŸ¡" if score >= 0.5 else "ğŸ”´"
                display_name = col.replace('_', ' ').title()
                print(f"{emoji} {display_name}: {score:.4f}")
        
        print("\n" + "-"*40)
        print("\nğŸ“‹ Ã–NCELÄ°KLÄ° METRÄ°KLER:")
        
        if 'faithfulness' in df.columns:
            faith_score = df['faithfulness'].mean()
            print(f"\n1ï¸âƒ£  FAITHFULNESS (Belgeye Sadakat): {faith_score:.4f}")
            print("   â†’ Cevaplar ne kadar belgelere dayalÄ±?")
            if faith_score >= 0.8:
                print("   âœ… MÃ¼kemmel! Cevaplar belgelere sadÄ±k.")
            elif faith_score >= 0.6:
                print("   âš ï¸ Ä°yi ama iyileÅŸtirilebilir.")
            else:
                print("   âŒ Dikkat! Model hallÃ¼sinasyon yapÄ±yor olabilir.")
        
        if 'llm_context_recall' in df.columns:
            recall_score = df['llm_context_recall'].mean()
            print(f"\n2ï¸âƒ£  CONTEXT RECALL (Retrieval Recall): {recall_score:.4f}")
            print("   â†’ Gerekli bilgi ne kadar baÅŸarÄ±yla bulunuyor?")
            if recall_score >= 0.8:
                print("   âœ… MÃ¼kemmel! Retrieval sistemi Ã§ok iyi Ã§alÄ±ÅŸÄ±yor.")
            elif recall_score >= 0.6:
                print("   âš ï¸ Orta dÃ¼zey. Retrieval iyileÅŸtirilebilir.")
            else:
                print("   âŒ ZayÄ±f. Retrieval sistemi gÃ¶zden geÃ§irilmeli.")
        
        # DetaylÄ± sonuÃ§larÄ± kaydet
        print("\n" + "="*60)
        print("ğŸ’¾ DetaylÄ± sonuÃ§lar 'ragas_results.csv' dosyasÄ±na kaydedildi.")
        print("="*60)
        
        df.to_csv("ragas_results.csv", index=False)
        
        # Soru bazlÄ± detaylarÄ± gÃ¶ster
        print("\nğŸ“Š SORU BAZLI DETAYLAR:")
        print("-"*60)
        for idx, row in df.iterrows():
            q = TEST_QUESTIONS[idx]["question"][:40] + "..."
            print(f"\n{idx+1}. {q}")
            for col in metric_columns:
                if col in df.columns:
                    val = row[col]
                    if isinstance(val, (int, float)) and not pd.isna(val):
                        emoji = "ğŸŸ¢" if val >= 0.7 else "ğŸŸ¡" if val >= 0.5 else "ğŸ”´"
                        print(f"   {emoji} {col}: {val:.3f}")
        
        return results
        
    except Exception as e:
        print(f"\nâŒ DeÄŸerlendirme hatasÄ±: {e}")
        import traceback
        traceback.print_exc()
        return None


def quick_test():
    """HÄ±zlÄ± bir test yap - sadece sistemi kontrol et."""
    print("\nğŸ§ª HÄ±zlÄ± Test - Sistem KontrolÃ¼")
    print("-"*40)
    
    test_q = "Fool Pathway'de Sequence 9 Seer'Ä±n yetenekleri nelerdir?"
    
    try:
        result = app.invoke({"question": test_q})
        print(f"âœ… Sistem Ã§alÄ±ÅŸÄ±yor!")
        print(f"\nSoru: {test_q}")
        print(f"\nCevap: {result.get('generation', 'Cevap alÄ±namadÄ±')[:500]}...")
        print(f"\nBulunan belge sayÄ±sÄ±: {len(result.get('documents', []))}")
        return True
    except Exception as e:
        print(f"âŒ Sistem hatasÄ±: {e}")
        return False


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--quick":
        quick_test()
    else:
        print("\nğŸ’¡ Ã–nce hÄ±zlÄ± test yapmak iÃ§in: python test_ragas.py --quick")
        print("   Tam deÄŸerlendirme iÃ§in: python test_ragas.py\n")
        run_evaluation()
